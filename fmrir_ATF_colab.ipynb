{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "455DrTfig4Vt",
    "outputId": "b40602cf-d977-4c16-8202-8a82161dc17d"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install wandb -qU\n",
    "\n",
    "# Log in to your W&B account\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "\n",
    "wandb.login(key=\"ec2cf1718868be26a8055412b556d952681ee0b6\")\n"
   ],
   "metadata": {
    "id": "diR6u8fHq2Px",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c515a274-33b4-44d5-a15a-f10d2bd7f9b2"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: No netrc file found, creating one.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mege-erdem3\u001B[0m (\u001B[33mege-erdem-king-s-college-london\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/egerdem/FM-RIR.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3_pN3qv_8UH",
    "outputId": "e2416f72-9043-4c0e-e8ba-3607f37178cc"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'FM-RIR'...\n",
      "remote: Enumerating objects: 78, done.\u001B[K\n",
      "remote: Counting objects: 100% (78/78), done.\u001B[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001B[K\n",
      "remote: Total 78 (delta 40), reused 63 (delta 25), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (78/78), 17.60 MiB | 17.57 MiB/s, done.\n",
      "Resolving deltas: 100% (40/40), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "P_LjloGUAA1C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# List contents of your Drive\n",
    "#import os\n",
    "#os.listdir('/content/drive/My Drive/')\n",
    "\n",
    "# Load a file from your Drive\n",
    "#with open('/content/drive/My Drive/FMRIR/fm_utils.py', 'r') as f:\n",
    "    #content = f.read()\n",
    "\n",
    "# Save a file to your Drive\n",
    "#with open('/content/drive/My Drive/new_file.txt', 'w') as f:\n",
    "    #f.write('This is a new file saved from Colab.')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/FMRIR')\n",
    "sys.path.append('/content/drive/My Drive')\n",
    "sys.path.append('/FMRIR')\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "\n",
    "from FMRIR.fm_utils import (ATFSliceSampler, GaussianConditionalProbabilityPath,\n",
    "                      ATFInpaintingTrainer, ATFUNet, LinearAlpha, LinearBeta)"
   ],
   "metadata": {
    "id": "EKF8Bb-U_80b"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "wandinit = True\n",
    "resume_from_checkpoint = None\n",
    "# resume_from_checkpoint = \"/Users/ege/Projects/FMRIR/experiments/SpecUNet_20250804-140641/checkpoints/ckpt_10.pt\"\n",
    "\n",
    "# --- Configuration ---\n",
    "config = {\n",
    "    \"data\": {\n",
    "        \"data_dir\": \"/content/drive/My Drive/ir_fs2000_s1024_m1331_room4.0x6.0x3.0_rt200/\",\n",
    "        \"src_splits\": {\n",
    "            \"train\": [0, 820],\n",
    "            \"valid\": [820, 922],\n",
    "            \"test\": [922, 1024],\n",
    "            \"all\": [0, 1024]}\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"ATFUNet\",\n",
    "        \"channels\": [32, 64, 128],\n",
    "        \"num_residual_layers\": 2,\n",
    "        \"t_embed_dim\": 40,\n",
    "        \"y_dim\": 4,\n",
    "        \"y_embed_dim\": 40\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"num_iterations\": 20,\n",
    "        \"batch_size\": 250,\n",
    "        \"lr\": 1e-3,\n",
    "        \"M\": 50,  # Number of observation points / mic recordings\n",
    "        \"eta\": 0.1\n",
    "    },\n",
    "    \"experiments_dir\": \"experiments\",\n",
    "}\n",
    "\n",
    "start_iteration = 0\n",
    "if resume_from_checkpoint and os.path.exists(resume_from_checkpoint):\n",
    "    checkpoint_dir = os.path.dirname(resume_from_checkpoint)\n",
    "    experiment_dir = os.path.dirname(checkpoint_dir)\n",
    "    experiment_name = os.path.basename(experiment_dir)\n",
    "\n",
    "    print(f\"Resuming training from checkpoint: {resume_from_checkpoint}\")\n",
    "    checkpoint = torch.load(resume_from_checkpoint, map_location=device)\n",
    "    start_iteration = checkpoint['iteration']\n",
    "\n",
    "    # Initialize wandb with the ID of the run you're resuming\n",
    "    wandb.login(key=\"ec2cf1718868be26a8055412b556d952681ee0b6\")\n",
    "    run_id = checkpoint['wandb_run_id']\n",
    "    wandb.init(project=\"FM-RIR\", id=run_id, resume=\"must\", config=config)\n",
    "\n",
    "else:\n",
    "    # --- Experiment Setup ---\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    experiment_name = f\"{config['model']['name']}_{timestamp}_iter{str(config['training']['num_iterations'])}\"\n",
    "    experiment_dir = os.path.join(config['experiments_dir'], experiment_name)\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize a new wandb run\n",
    "    if wandinit:\n",
    "        wandb.login(key=\"ec2cf1718868be26a8055412b556d952681ee0b6\")\n",
    "        run = wandb.init(project=\"FM-RIR\", name=experiment_name, config=config)\n",
    "        config['wandb_run_id'] = run.id\n",
    "\n",
    "    CONFIG_SAVE_PATH = os.path.join(experiment_dir, \"config.json\")\n",
    "\n",
    "    with open(CONFIG_SAVE_PATH, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    print(f\"Experiment setup. Config saved to {CONFIG_SAVE_PATH}\")"
   ],
   "metadata": {
    "id": "S6CmWdrfg1sj",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "outputId": "e91996bf-7623-4993-df71-bb8f4be0f592"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ATFUNet_20250805-114318_iter20</strong> at: <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/zbr0j6uu' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/zbr0j6uu</a><br> View project at: <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_114318-zbr0j6uu/logs</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250805_114550-h2z4ts56</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/h2z4ts56' target=\"_blank\">ATFUNet_20250805-114550_iter20</a></strong> to <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/h2z4ts56' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/h2z4ts56</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Experiment setup. Config saved to experiments/ATFUNet_20250805-114550_iter20/config.json\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# run = wandb.init(\n",
    "#     # Set the wandb entity where your project will be logged (generally your team name).\n",
    "#     entity=\"ege-erdem-king-s-college-london\",\n",
    "#     # Set the wandb project where this run will be logged.\n",
    "#     project=\"FM-RIR\",\n",
    "#     # Track hyperparameters and run metadata.\n",
    "#     config=config\n",
    "#     )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "POGMl6wSrVex",
    "outputId": "cd3c7d82-58cc-48c8-f85e-421344be0a03"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250730_112156-xhdp5pue</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/xhdp5pue' target=\"_blank\">celestial-dream-4</a></strong> to <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/xhdp5pue' target=\"_blank\">https://wandb.ai/ege-erdem-king-s-college-london/FM-RIR/runs/xhdp5pue</a>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "MODEL_SAVE_PATH = os.path.join(experiment_dir, \"model.pt\")\n",
    "CHECKPOINT_DIR = os.path.join(experiment_dir, \"checkpoints\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Data Loading ---\n",
    "data_cfg = config['data']\n",
    "\n",
    "# we calculate normalization stats from data the model will be trained on.\n",
    "# --- Instantiate Samplers for each split (only ONCE) ---\n",
    "\n",
    "atf_train_sampler = ATFSliceSampler(\n",
    "    data_path=data_cfg['data_dir'], mode='train', src_splits=data_cfg['src_splits']).to(device)\n",
    "\n",
    "atf_valid_sampler = ATFSliceSampler(\n",
    "    data_path=data_cfg['data_dir'], mode='valid', src_splits=data_cfg['src_splits']).to(device)\n",
    "\n",
    "# --- Calculate stats from the single training sampler instance ---\n",
    "spec_mean = atf_train_sampler.slices.mean()\n",
    "spec_std = atf_train_sampler.slices.std()\n",
    "print(f\"\\nCalculated Mean: {spec_mean:.4f}, Std: {spec_std:.4f} (from training set)\")\n",
    "\n",
    "# --- Define and apply the transform to the existing samplers ---\n",
    "# We pad the 11x11 grid to 12x12 according to the torch documentation order:  left, top, right and bottom\n",
    "padding = (0, 0, 1, 1) # right col and bottom row padded!\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding, padding_mode='reflect'),\n",
    "    transforms.Normalize((spec_mean,), (spec_std,)),\n",
    "])\n",
    "\n",
    "atf_train_sampler.transform = transform\n",
    "atf_valid_sampler.transform = transform\n",
    "\n",
    "atf_valid_sampler.plot()\n",
    "\n",
    "sample_spec, _ = atf_train_sampler.sample(1) # The sample_spec will now have shape (1, 64, 11, 11)\n",
    "# The shape for the path object should be [C, H, W]\n",
    "atf_shape = list(sample_spec.shape[1:]) # This will be [64, 11, 11]\n",
    "print(f\"ATF Slice shape for Path: {atf_shape}\")\n",
    "\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = atf_train_sampler,\n",
    "    p_simple_shape = atf_shape,\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "# --- Model and Trainer Initialization ---\n",
    "model_cfg = config['model']\n",
    "training_cfg = config['training']\n",
    "\n",
    "atf_unet = ATFUNet(\n",
    "    channels=model_cfg['channels'],  # Same as MNIST version\n",
    "    num_residual_layers=model_cfg['num_residual_layers'],  # Same as MNIST version\n",
    "    t_embed_dim=model_cfg['t_embed_dim'],  # Same as MNIST version\n",
    "    y_dim=model_cfg['y_dim'],  # new: 6D coordinates for source and microphone positions\n",
    "    y_embed_dim=model_cfg['y_embed_dim'],  # Same as MNIST version\n",
    ").to(device)\n",
    "\n",
    "trainer = ATFInpaintingTrainer(\n",
    "    path=path,\n",
    "    model=atf_unet,\n",
    "    eta=training_cfg['eta'],\n",
    "    M = 5, #Number of observation points / mic recordings\n",
    "    y_dim=model_cfg['y_dim'],\n",
    ")\n",
    "\n",
    "if start_iteration > 0:\n",
    "    atf_unet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    trainer.y_null.data = checkpoint['y_null'].to(device)\n",
    "\n",
    "# --- Visualize the masking ---\n",
    "trainer.visualize_masking(crop=True, sample_idx=15, freq_idx=20)\n",
    "\n",
    "# --- Training ---\n",
    "print(f\"\\n--- Starting Training for experiment: {experiment_name} ---\")\n",
    "trainer.train(\n",
    "    num_iterations=training_cfg['num_iterations'],\n",
    "    device=device,\n",
    "    lr=training_cfg['lr'],\n",
    "    batch_size=training_cfg['batch_size'],\n",
    "    valid_sampler=atf_valid_sampler,\n",
    "    save_path=MODEL_SAVE_PATH,\n",
    "    checkpoint_path=CHECKPOINT_DIR,\n",
    "    checkpoint_interval=20,  # Save a checkpoint every 1000 iterations\n",
    "    m=training_cfg['M'],  # Number of observation points / mic recordings\n",
    "    start_iteration=start_iteration,  # Start from 0 or the loaded iteration\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# --- Finalizing the Run ---\n",
    "# Log the best model as a wandb Artifact for easy access later\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(\"Logging best model to W&B Artifacts...\")\n",
    "    best_model_artifact = wandb.Artifact(f\"{wandb.run.name}-best-model\", type=\"model\")\n",
    "    best_model_artifact.add_file(MODEL_SAVE_PATH)\n",
    "    wandb.log_artifact(best_model_artifact)\n",
    "\n",
    "wandb.finish()\n",
    "print(\"Training complete and wandb run finished.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "hcjX9kLSjpx5",
    "outputId": "68e17210-8fa2-4f4b-953f-3c36cfcd7254"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing ATF train data from .npz files...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading train NPZ files:   1%|‚ñè         | 11/820 [00:05<06:28,  2.08it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-3972495902.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m# --- Instantiate Samplers for each split (only ONCE) ---\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m atf_train_sampler = ATFSliceSampler(\n\u001B[0m\u001B[1;32m     12\u001B[0m     data_path=data_cfg['data_dir'], mode='train', src_splits=data_cfg['src_splits']).to(device)\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/FMRIR/fm_utils.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data_path, mode, src_splits, transform)\u001B[0m\n\u001B[1;32m    784\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0msrc_id\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_indices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mf\"Loading {mode} NPZ files\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    785\u001B[0m                 \u001B[0mnpz_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf\"data_s{src_id + 1:04d}.npz\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 786\u001B[0;31m                 \u001B[0;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnpz_file\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    787\u001B[0m                     \u001B[0matf_mags\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'atf_mag_algn'\u001B[0m\u001B[0;34m]\u001B[0m   \u001B[0;31m# Shape: (1331, 64)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    788\u001B[0m                     \u001B[0mmic_pos\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'posMic'\u001B[0m\u001B[0;34m]\u001B[0m          \u001B[0;31m# Shape: (1331, 3)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    470\u001B[0m             \u001B[0;31m# Potentially transfer file ownership to NpzFile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    471\u001B[0m             \u001B[0mstack\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 472\u001B[0;31m             ret = NpzFile(fid, own_fid=own_fid, allow_pickle=allow_pickle,\n\u001B[0m\u001B[1;32m    473\u001B[0m                           \u001B[0mpickle_kwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpickle_kwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m                           max_header_size=max_header_size)\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, fid, own_fid, allow_pickle, pickle_kwargs, max_header_size)\u001B[0m\n\u001B[1;32m    188\u001B[0m         \u001B[0;31m# Import is postponed to here since zipfile depends on gzip, an\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;31m# optional component of the so-called standard library.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 190\u001B[0;31m         \u001B[0m_zip\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzipfile_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    191\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_files\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_zip\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamelist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfiles\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001B[0m in \u001B[0;36mzipfile_factory\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[0;32mimport\u001B[0m \u001B[0mzipfile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'allowZip64'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mzipfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mZipFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.11/zipfile.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001B[0m\n\u001B[1;32m   1311\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1312\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1313\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_RealGetContents\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1314\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'w'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'x'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1315\u001B[0m                 \u001B[0;31m# set the modified flag so central directory gets written\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.11/zipfile.py\u001B[0m in \u001B[0;36m_RealGetContents\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1374\u001B[0m         \u001B[0mfp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1375\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1376\u001B[0;31m             \u001B[0mendrec\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_EndRecData\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1377\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1378\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mBadZipFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"File is not a zip file\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.11/zipfile.py\u001B[0m in \u001B[0;36m_EndRecData\u001B[0;34m(fpin)\u001B[0m\n\u001B[1;32m    301\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 303\u001B[0;31m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfpin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    304\u001B[0m     if (len(data) == sizeEndCentDir and\n\u001B[1;32m    305\u001B[0m         \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mstringEndArchive\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ]
}
